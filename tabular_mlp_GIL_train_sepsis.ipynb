{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42c8acb0-9260-43b0-a0b0-e0dda245eae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:50: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os \n",
    "import multiprocessing as mp\n",
    "from qnetwork import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "import scipy.stats as stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95fbf3d1-ffe0-4cd6-bf1d-57076dce6e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-replay_buffer'], dest='replay_buffer', nargs=None, const=None, default=10000, type=<class 'int'>, choices=None, help='Size of experience replay buffer for training actor and critic. Default to 10**4.', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = tf.contrib.rnn\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"-no_gpu\", dest='no_gpu', action='store_true', help=\"Train w/o using GPUs\")\n",
    "parser.add_argument(\"-gpu\", \"--gpu_idx\", type=int, help=\"Select which GPU to use DEFAULT=0\", default=0)\n",
    "parser.add_argument(\"-lr_prediction_model\", type=float, help=\"Set learning rate for training the MLP prediction model DEFAULT=0.001\", default=0.001)\n",
    "parser.add_argument(\"-lr_actor\", type=float, help=\"Set learning rate for training the actor DEFAULT=0.0001\", default=0.0001)\n",
    "parser.add_argument(\"-lr_critic\", type=float, help=\"Set learning rate for training the critic DEFAULT=0.001\", default=0.001)\n",
    "parser.add_argument(\"-decay_step\", type=int, help=\"Set exponential decay step DEFAULT=750\", default=750)\n",
    "parser.add_argument(\"-decay_rate\", type=float, help=\"Set exponential decay rate DEFAULT=1.0\", default=0.9)\n",
    "parser.add_argument(\"-decay_lr_actor\", type=float, help=\"Set decay rate the learning rate of the actor DEFAULT=0.965\", default=0.965)\n",
    "parser.add_argument(\"-decay_lr_critic\", type=float, help=\"Set decay rate the learning rate of the critic DEFAULT=0.965\", default=0.965)\n",
    "parser.add_argument(\"-training_steps\", type=int, help=\"Set max number of training epochs DEFAULT=3000\", default=3000)\n",
    "parser.add_argument(\"-seed\", type=int, help=\"Set random seed\", default=2599)\n",
    "parser.add_argument(\"-exploration_prob\", type=float, help=\"Initial probability of random exploration (p3 in Appendix D) in the behavioral policy\", default=0.4)\n",
    "parser.add_argument(\"-heuristic_prob\", type=float, help=\"Initial probability of following the heuristic (p2 in Appendix D) in the behavioral policy\", default=0.5)\n",
    "parser.add_argument(\"-exploration_prob_decay\", type=float, help=\"Rate of decaying the probability of random exploration in each step\", default=0.999)\n",
    "parser.add_argument(\"-heuristic_prob_decay\", type=float, help=\"Rate of decaying the probability of following the heuristic in each step\", default=0.999)\n",
    "parser.add_argument(\"-replay_buffer\", type=int, help=\"Size of experience replay buffer for training actor and critic. Default to 10**4.\", default=10**4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f13ca1-bb99-42cb-807b-d3374f282429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(decay_lr_actor=0.965, decay_lr_critic=0.965, decay_rate=0.9, decay_step=750, exploration_prob=0.4, exploration_prob_decay=0.999, gpu_idx=0, heuristic_prob=0.5, heuristic_prob_decay=0.999, lr_actor=0.0001, lr_critic=0.001, lr_prediction_model=0.001, no_gpu=False, replay_buffer=10000, seed=2599, training_steps=3000)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = parser.parse_args(args=[])\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93658ad-f9fc-4e32-bdc2-437b6e5e5a91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:3: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:10: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:130: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:135: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:95: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\python3.7\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:144: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:148: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:148: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:150: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:150: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:151: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:37: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:47: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:137: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\python3.7\\lib\\site-packages\\tensorflow_core\\python\\ops\\losses\\losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:186: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_13944\\1144625124.py:191: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Step 10, Minibatch Loss= , Max Final Accuracy=  0.985853, Max AUC=  0.463055, Max AP=  0.012927\n",
      "Step 20, Minibatch Loss= , Max Final Accuracy=  0.985853, Max AUC=  0.463055, Max AP=  0.012927\n",
      "Step 30, Minibatch Loss= , Max Final Accuracy=  0.985853, Max AUC=  0.463055, Max AP=  0.012927\n",
      "Step 40, Minibatch Loss= , Max Final Accuracy=  0.985853, Max AUC=  0.463055, Max AP=  0.012927\n"
     ]
    }
   ],
   "source": [
    "    if not args.no_gpu:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_idx)\n",
    "        session_config = tf.ConfigProto(log_device_placement=False)\n",
    "        session_config.gpu_options.allow_growth = True\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "        session_config = tf.ConfigProto(log_device_placement=False)\n",
    "    SEED = args.seed\n",
    "    np.random.seed(SEED)\n",
    "    tf.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    if not os.path.exists(\"./saved_model\"):\n",
    "            os.mkdir(\"./saved_model\")\n",
    "    if not os.path.exists(\"./stats\"):\n",
    "            os.mkdir(\"./stats\")\n",
    "    if not os.path.exists(\"./stats/rl_log\"):\n",
    "            os.mkdir(\"./stats/rl_log\")\n",
    "\n",
    "    # normal_train = np.loadtxt(\"./data/normal_train_all_35_missing.txt\")\n",
    "    # abnormal_train = np.loadtxt(\"./data/abnormal_train_all_35_missing.txt\")\n",
    "    # normal_test = np.loadtxt(\"./data/normal_test_all_35_missing.txt\")\n",
    "    # abnormal_test = np.loadtxt(\"./data/abnormal_test_all_35_missing.txt\")\n",
    "    normal_train = np.loadtxt(\"./data/trainA_normal_sepsis.txt\")\n",
    "    abnormal_train = np.loadtxt(\"./data/trainA_abnormal_sepsis.txt\")\n",
    "    normal_test = np.loadtxt(\"./data/testB_normal_sepsis.txt\")\n",
    "    abnormal_test = np.loadtxt(\"./data/testB_abnormal_sepsis.txt\")\n",
    "\n",
    "    data_train = np.vstack([normal_train, abnormal_train]).astype(np.float32)\n",
    "    data_label_train = np.concatenate([np.zeros(len(normal_train)), np.ones(len(abnormal_train))]).astype(np.int32)\n",
    "    data_mask_train = np.isnan(data_train).astype(np.float32)\n",
    "\n",
    "    data_test = np.vstack([normal_test, abnormal_test]).astype(np.float32)\n",
    "    data_label_test = np.concatenate([np.zeros(len(normal_test)), np.ones(len(abnormal_test))]).astype(np.int32)\n",
    "    data_mask_test = np.isnan(data_test).astype(np.float32)\n",
    "\n",
    "\n",
    "    nan_replacement = 0.\n",
    "\n",
    "    data_train[np.isnan(data_train)] = nan_replacement\n",
    "    data_test[np.isnan(data_test)] = nan_replacement\n",
    "\n",
    "\n",
    "    # Setting up the truncated normal distribution for exploration\n",
    "\n",
    "    lower, upper = 0, 1\n",
    "    mu, sigma = 0, 0.2\n",
    "    left_truncnorm = stats.truncnorm(\n",
    "        (lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "    right_truncnorm = stats.truncnorm(\n",
    "        (lower - 1.) / sigma, (upper - 1.) / sigma, loc=1., scale=sigma)\n",
    "\n",
    "    # fig, ax = plt.subplots(1, sharex=True)\n",
    "    # ax.hist(np.concatenate([left_truncnorm.rvs(10000),right_truncnorm.rvs(10000)]), normed=True)\n",
    "\n",
    "    np.random.seed(SEED)\n",
    "    tf.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    # RL learning rates\n",
    "    actor_lr, critic_lr = args.lr_actor, args.lr_critic\n",
    "\n",
    "    # Prediction Model Parameters\n",
    "    start_learning_rate = args.lr_prediction_model\n",
    "    decay_step = args.decay_step\n",
    "    decay_rate = args.decay_rate\n",
    "\n",
    "    # Threshold for decaying RL learning rates\n",
    "    rl_reward_thres_for_decay = -25\n",
    "\n",
    "    training_steps = args.training_steps\n",
    "    batch_size = 128 # must be a multiple of 4\n",
    "\n",
    "    # num_input = normal_train.shape[1]\n",
    "    num_input = data_train.shape[1]\n",
    "    timesteps = 1 # timesteps\n",
    "    num_classes = 2 \n",
    "\n",
    "    display_step = 10\n",
    "\n",
    "    #weights = [1000, 1000] (decrese node numbers)\n",
    "    weights = [5, 5]\n",
    "    \n",
    "    gpu = 0\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    file_appendix = \"TAB_MLP_GIL_\" + str(start_learning_rate) + \"_\" + str(decay_step) + \"_\" + str(decay_rate) + \"_\" + str(actor_lr) + \"_\" + str(critic_lr)\n",
    "\n",
    "\n",
    "    def build_net(x, is_training=True, reuse=tf.AUTO_REUSE, graph=graph):\n",
    "\n",
    "        with graph.as_default():\n",
    "\n",
    "            with tf.variable_scope(\"NN\", reuse=tf.AUTO_REUSE) as scope:\n",
    "                with slim.arg_scope([slim.fully_connected], \n",
    "                                        activation_fn=tf.nn.relu,\n",
    "                                        weights_initializer=tf.random_uniform_initializer(0.001, 0.01),\n",
    "                                        weights_regularizer=slim.l2_regularizer(0.1),\n",
    "                                        biases_regularizer=slim.l2_regularizer(0.1),\n",
    "                                        normalizer_fn = slim.batch_norm,\n",
    "                                        normalizer_params = {\"is_training\": is_training},\n",
    "                                        reuse = reuse,\n",
    "                                        scope = scope):\n",
    "\n",
    "                    fc1 = slim.fully_connected(x, weights[0], scope='fc1')\n",
    "                    fc2 = slim.fully_connected(fc1, weights[1], scope='fc2')\n",
    "                    logits = slim.fully_connected(fc2,num_classes,activation_fn=None, weights_regularizer=None, normalizer_fn=None, scope='logits')\n",
    "                    pred = slim.softmax(logits, scope='pred')\n",
    "\n",
    "                    return logits, pred, fc1\n",
    "\n",
    "\n",
    "    def gen_train():\n",
    "        for i in range(data_train.shape[0]):\n",
    "            label = np.zeros(2)\n",
    "            label[data_label_train[i]] = 1.\n",
    "            yield data_train[i], label, data_mask_train[i]\n",
    "\n",
    "    def gen_test():\n",
    "        for i in range(data_test.shape[0]):\n",
    "            label = np.zeros(2)\n",
    "            label[data_label_test[i]] = 1.\n",
    "            yield data_test[i], label, data_mask_test[i]\n",
    "\n",
    "\n",
    "    with graph.as_default():\n",
    "\n",
    "        dataset_train = tf.data.Dataset.from_generator(gen_train, (tf.float32, tf.float32, tf.int32), ([normal_train.shape[1]],[2],[normal_train.shape[1]])).repeat(30000).shuffle(5000).batch(batch_size)\n",
    "        input_train, label_train, mask_train = dataset_train.make_one_shot_iterator().get_next()\n",
    "\n",
    "        dataset_test = tf.data.Dataset.from_generator(gen_test, (tf.float32, tf.float32, tf.int32), ([normal_train.shape[1]],[ 2],[normal_train.shape[1]])).repeat(30000).batch(data_test.shape[0])\n",
    "        input_test, label_test, mask_test = dataset_test.make_one_shot_iterator().get_next()\n",
    "\n",
    "        input_train_holder = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.float32)\n",
    "        label_train_holder = tf.placeholder(shape=[batch_size, num_classes], dtype=tf.float32)\n",
    "        mask_train_holder = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.int32)\n",
    "        logits, prediction, feature = build_net(input_train_holder)\n",
    "\n",
    "        all_test = data_test\n",
    "\n",
    "        logits_final, pred_final, _ = build_net(input_test, is_training=False)\n",
    "\n",
    "        fc_variables = [v for v in tf.trainable_variables() if v.name.find(\"NN\")!=-1]\n",
    "\n",
    "        #loss_op = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_train_holder) + tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope=\"NN\"))\n",
    "        # increase weights of entropy\n",
    "        loss_op = tf.nn.weighted_cross_entropy_with_logits(logits=logits, labels=label_train_holder, pos_weight=50) + tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope=\"NN\"))\n",
    "        loss_mean = tf.reduce_mean(loss_op, axis=0)\n",
    "        learning_rate = tf.train.exponential_decay(start_learning_rate, tf.train.get_or_create_global_step(), decay_steps=decay_step, decay_rate=decay_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # Get the encoding weights and obtain the gradients using regular SGD sovler\n",
    "\n",
    "        grads = tf.vectorized_map(lambda x: optimizer.compute_gradients(x, fc_variables), loss_op)\n",
    "        grads = [g[0] for g in grads]\n",
    "\n",
    "        # Apply importance to the gradients calculated from regular SGD solver\n",
    "\n",
    "        grad_importance = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.float32)\n",
    "        grads[0] = grads[0]*grad_importance[...,tf.newaxis]\n",
    "\n",
    "        grads = [tf.reduce_mean(g,axis=0) for g in grads]\n",
    "        \n",
    "        with tf.control_dependencies(update_ops):\n",
    "            grads_update_op = optimizer.apply_gradients(zip(grads, fc_variables))\n",
    "\n",
    "        train_correct_pred = tf.equal(tf.cast(tf.argmax(prediction, 1),tf.float32), tf.cast(tf.argmax(label_train_holder, 1),tf.float32) )\n",
    "        train_accuracy = tf.reduce_mean(tf.cast(train_correct_pred, tf.float32))\n",
    "        train_kld = tf.keras.losses.KLDivergence()(prediction, label_train_holder)\n",
    "\n",
    "        final_correct_pred = tf.equal(tf.argmax(pred_final, 1), tf.argmax(label_test, 1))\n",
    "        final_accuracy = tf.reduce_mean(tf.cast(final_correct_pred, tf.float32))\n",
    "        final_kld = tf.keras.losses.KLDivergence()(pred_final, label_test)\n",
    "\n",
    "        max_final_acc = tf.Variable(0, dtype=tf.float32, name=\"max_final_acc\", trainable=False)\n",
    "        assign_max_final_acc = max_final_acc.assign(final_accuracy)\n",
    "        \n",
    "        final_score = pred_final[:,1]\n",
    "\n",
    "    with graph.as_default():\n",
    "        actor = Actor(graph=graph, state_dim=num_input*timesteps*2+weights[0]+num_classes, action_dim=num_input*timesteps, learning_rate=actor_lr, tau=0.001, batch_size=batch_size, save_path=\"./saved_model/\"+file_appendix+\"/actor.ckpt\")\n",
    "        critic = Critic(graph=graph, state_dim=num_input*timesteps*2+weights[0]+num_classes, action_dim=num_input*timesteps, learning_rate=critic_lr, tau=0.001, gamma=0.99, save_path=\"./saved_model/\"+file_appendix+\"/critic.ckpt\")\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session(config=session_config, graph=graph) as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Probability of random exploration (p3 in Appendix D) in the behavioral policy\n",
    "        ## This probability will be decayed exponentially during training\n",
    "        EXPLORATION_RATE = args.exploration_prob\n",
    "\n",
    "        # Probability of following the heuristic (p2 in Appendix D) in the behavioral policy\n",
    "        ## This probability will be decayed exponentially during training\n",
    "        GUIDE_RATE = args.heuristic_prob\n",
    "\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "\n",
    "        data_in, label_in, s_mask = sess.run([input_train, label_train, mask_train])\n",
    "        s_1, s_2 = sess.run([logits, feature], feed_dict = {input_train_holder:data_in, label_train_holder:label_in, mask_train_holder:s_mask})\n",
    "        s = np.hstack([data_in,s_mask,s_1,s_2])\n",
    "\n",
    "        reward_list = []\n",
    "        ave_max_q_list = []\n",
    "        replay_buffer = ReplayBuffer(args.replay_buffer, random_seed=SEED)\n",
    "\n",
    "        # Run the initializer\n",
    "\n",
    "\n",
    "        max_auc = 0.\n",
    "        max_ap = 0.\n",
    "        max_acc = 0.\n",
    "        min_kld = 1000.\n",
    "\n",
    "        actor.update_target_network(sess)\n",
    "        critic.update_target_network(sess)\n",
    "\n",
    "        for step in range(training_steps):\n",
    "            rand_num = np.random.rand(1)\n",
    "\n",
    "            if rand_num <= EXPLORATION_RATE:\n",
    "                a = np.concatenate([left_truncnorm.rvs(num_input*(timesteps//2)*batch_size),right_truncnorm.rvs(num_input*(timesteps//2+1)*batch_size)])\n",
    "                np.random.shuffle(a)\n",
    "                a = a.reshape(batch_size,-1).astype(np.float32)\n",
    "\n",
    "            elif rand_num <= GUIDE_RATE+EXPLORATION_RATE and rand_num > EXPLORATION_RATE:\n",
    "                a = (1-s_mask).astype(np.float32)\n",
    "\n",
    "            else:\n",
    "                a = actor.predict(s, sess)\n",
    "\n",
    "            _, kld, test_kld = sess.run([grads_update_op, train_kld, final_kld], feed_dict={grad_importance:a, input_train_holder:data_in, label_train_holder:label_in, mask_train_holder:s_mask})\n",
    "            acc = sess.run([final_accuracy])\n",
    "            data_in, label_in, s2_mask = sess.run([input_train, label_train, mask_train])\n",
    "            s2_1, s2_2 = sess.run([logits, feature], feed_dict = {input_train_holder:data_in, label_train_holder:label_in})\n",
    "            s2 = np.hstack([data_in,s2_mask,s2_1,s2_2])\n",
    "\n",
    "            r = np.repeat(-kld, batch_size)\n",
    "            replay_buffer.add_batch([list(i) for i in zip(s,a,r,s2)])\n",
    "\n",
    "            if replay_buffer.size() > batch_size:\n",
    "                s_batch, a_batch, r_batch, s2_batch = replay_buffer.sample_batch(batch_size)\n",
    "\n",
    "                # Calculate targets\n",
    "                target_q = critic.predict_target(\n",
    "                    s2_batch, actor.predict_target(s2_batch, sess), sess)\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(batch_size):\n",
    "                    y_i.append(r_batch[k] + critic.gamma * target_q[k])\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                predicted_q_value, _ = critic.train(\n",
    "                    s_batch, a_batch, np.reshape(y_i, (batch_size, 1)), step, sess)\n",
    "\n",
    "                ave_max_q = np.amax(predicted_q_value)\n",
    "                ave_max_q_list += [ave_max_q]\n",
    "\n",
    "                # Update the actor policy using the sampled gradient\n",
    "                a_outs = actor.predict(s_batch, sess)\n",
    "                grads = critic.action_gradients(s_batch, a_outs, sess)\n",
    "                actor.train(s_batch, grads[0], step, sess)\n",
    "\n",
    "                # Update target networks\n",
    "                actor.update_target_network(sess)\n",
    "                critic.update_target_network(sess)\n",
    "\n",
    "            s = s2\n",
    "            s_mask = s2_mask\n",
    "\n",
    "            reward_list += [r[0]]\n",
    "            \n",
    "            if EXPLORATION_RATE > 0.2:\n",
    "                EXPLORATION_RATE = EXPLORATION_RATE * args.exploration_prob_decay\n",
    "            if GUIDE_RATE > 0.3:\n",
    "                GUIDE_RATE = GUIDE_RATE * args.heuristic_prob_decay\n",
    "\n",
    "\n",
    "            if step % display_step == 0 and step > 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc, train_acc = sess.run([loss_mean, final_accuracy, train_accuracy], feed_dict = {input_train_holder:data_in, label_train_holder:label_in})\n",
    "                auc = roc_auc_score(data_label_test, final_score.eval())\n",
    "                ap = average_precision_score(data_label_test, final_score.eval())\n",
    "                if np.mean(reward_list[-display_step:]) >= rl_reward_thres_for_decay:\n",
    "                    actor.decay_learning_rate(args.decay_lr_actor, sess)\n",
    "                    critic.decay_learning_rate(args.decay_lr_critic, sess)\n",
    "\n",
    "                if acc > max_acc:\n",
    "                    max_acc = acc\n",
    "                    max_auc = auc\n",
    "                    max_ap = ap\n",
    "                    min_kld = test_kld\n",
    "                    sess.run(assign_max_final_acc)\n",
    "                    saver.save(sess, \"./saved_model/\"+file_appendix+\"/best.ckpt\")\n",
    "                print (\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(np.mean(loss)) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(train_acc) + \\\n",
    "                      \", Max Final Accuracy= \", \"{:6f}\".format(max_final_acc.eval()) + \\\n",
    "                      \", Max AUC= \", \"{:6f}\".format(max_auc) + \\\n",
    "                      \", Max AP= \", \"{:6f}\".format(max_ap))\n",
    "                with open(\"./stats/rl_log/\" + file_appendix + \".txt\", \"a\") as myfile:\n",
    "                    myfile.write(\"Step \" + str(step) + \", Reward=\" + str(np.sum(reward_list[-display_step:])) + \", Minibatch Loss= \" + \"{:.4f}\".format(np.mean(loss)) + \", Training Accuracy= \" + \"{:.3f}\".format(train_acc) + \", Max Final Accuracy= \" + \"{:6f}\".format(max_final_acc.eval()) + \", Exploration= \" + \"{:6f}\".format(EXPLORATION_RATE) + \", Guide= \" + \"{:6f}\".format(GUIDE_RATE) + \"\\n\")\n",
    "        print (\"Optimization Finished!\")\n",
    "\n",
    "        print (\"Testing Accuracy:\", sess.run(max_final_acc))\n",
    "        print (\"Testing AUC:\", max_auc)\n",
    "        with open(\"./stats/TAB_GIL.txt\", \"a\") as myfile:\n",
    "            myfile.write(\"%.9f\\t%i\\t%.3f\\t%i\\t%i\\t%.9f\\t%.9f\\t%.6f\\t%.6f\\t%.6f\\n\" %(start_learning_rate, decay_step, decay_rate, weights[0], weights[1], actor_lr, critic_lr, max_final_acc.eval(), max_auc, max_ap))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bdd706-b8f9-4aec-b44d-7e493edfd781",
   "metadata": {},
   "source": [
    "### add dropoff layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d77ead-3a59-4138-a63d-a303489dcadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:3: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:10: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:131: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:136: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\python3.7\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:145: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:149: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:149: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:151: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:151: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:152: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:37: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:47: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:137: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\python3.7\\lib\\site-packages\\tensorflow_core\\python\\ops\\losses\\losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_11304\\3373454497.py:192: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Step 10, Minibatch Loss= 17.2446, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.438640, Max AP=  0.012243\n",
      "Step 20, Minibatch Loss= 16.9394, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.438640, Max AP=  0.012243\n"
     ]
    }
   ],
   "source": [
    "    if not args.no_gpu:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_idx)\n",
    "        session_config = tf.ConfigProto(log_device_placement=False)\n",
    "        session_config.gpu_options.allow_growth = True\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "        session_config = tf.ConfigProto(log_device_placement=False)\n",
    "    SEED = args.seed\n",
    "    np.random.seed(SEED)\n",
    "    tf.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    if not os.path.exists(\"./saved_model\"):\n",
    "            os.mkdir(\"./saved_model\")\n",
    "    if not os.path.exists(\"./stats\"):\n",
    "            os.mkdir(\"./stats\")\n",
    "    if not os.path.exists(\"./stats/rl_log\"):\n",
    "            os.mkdir(\"./stats/rl_log\")\n",
    "\n",
    "    # normal_train = np.loadtxt(\"./data/normal_train_all_35_missing.txt\")\n",
    "    # abnormal_train = np.loadtxt(\"./data/abnormal_train_all_35_missing.txt\")\n",
    "    # normal_test = np.loadtxt(\"./data/normal_test_all_35_missing.txt\")\n",
    "    # abnormal_test = np.loadtxt(\"./data/abnormal_test_all_35_missing.txt\")\n",
    "    normal_train = np.loadtxt(\"./data/trainA_normal_sepsis.txt\")\n",
    "    abnormal_train = np.loadtxt(\"./data/trainA_abnormal_sepsis.txt\")\n",
    "    normal_test = np.loadtxt(\"./data/testB_normal_sepsis.txt\")\n",
    "    abnormal_test = np.loadtxt(\"./data/testB_abnormal_sepsis.txt\")\n",
    "\n",
    "    data_train = np.vstack([normal_train, abnormal_train]).astype(np.float32)\n",
    "    data_label_train = np.concatenate([np.zeros(len(normal_train)), np.ones(len(abnormal_train))]).astype(np.int32)\n",
    "    data_mask_train = np.isnan(data_train).astype(np.float32)\n",
    "\n",
    "    data_test = np.vstack([normal_test, abnormal_test]).astype(np.float32)\n",
    "    data_label_test = np.concatenate([np.zeros(len(normal_test)), np.ones(len(abnormal_test))]).astype(np.int32)\n",
    "    data_mask_test = np.isnan(data_test).astype(np.float32)\n",
    "\n",
    "\n",
    "    nan_replacement = 0.\n",
    "\n",
    "    data_train[np.isnan(data_train)] = nan_replacement\n",
    "    data_test[np.isnan(data_test)] = nan_replacement\n",
    "\n",
    "\n",
    "    # Setting up the truncated normal distribution for exploration\n",
    "\n",
    "    lower, upper = 0, 1\n",
    "    mu, sigma = 0, 0.2\n",
    "    left_truncnorm = stats.truncnorm(\n",
    "        (lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "    right_truncnorm = stats.truncnorm(\n",
    "        (lower - 1.) / sigma, (upper - 1.) / sigma, loc=1., scale=sigma)\n",
    "\n",
    "    # fig, ax = plt.subplots(1, sharex=True)\n",
    "    # ax.hist(np.concatenate([left_truncnorm.rvs(10000),right_truncnorm.rvs(10000)]), normed=True)\n",
    "\n",
    "    np.random.seed(SEED)\n",
    "    tf.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    # RL learning rates\n",
    "    actor_lr, critic_lr = args.lr_actor, args.lr_critic\n",
    "\n",
    "    # Prediction Model Parameters\n",
    "    start_learning_rate = args.lr_prediction_model\n",
    "    decay_step = args.decay_step\n",
    "    decay_rate = args.decay_rate\n",
    "\n",
    "    # Threshold for decaying RL learning rates\n",
    "    rl_reward_thres_for_decay = -25\n",
    "\n",
    "    training_steps = args.training_steps\n",
    "    batch_size = 128 # must be a multiple of 4\n",
    "\n",
    "    # num_input = normal_train.shape[1]\n",
    "    num_input = data_train.shape[1]\n",
    "    timesteps = 1 # timesteps\n",
    "    num_classes = 2 \n",
    "\n",
    "    display_step = 10\n",
    "\n",
    "    #weights = [1000, 1000] (decrese node numbers)\n",
    "    weights = [5, 5]\n",
    "    \n",
    "    gpu = 0\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    file_appendix = \"TAB_MLP_GIL_\" + str(start_learning_rate) + \"_\" + str(decay_step) + \"_\" + str(decay_rate) + \"_\" + str(actor_lr) + \"_\" + str(critic_lr)\n",
    "\n",
    "\n",
    "    def build_net(x, is_training=True, reuse=tf.AUTO_REUSE, graph=graph):\n",
    "\n",
    "        with graph.as_default():\n",
    "\n",
    "            with tf.variable_scope(\"NN\", reuse=tf.AUTO_REUSE) as scope:\n",
    "                with slim.arg_scope([slim.fully_connected], \n",
    "                                        activation_fn=tf.nn.relu,\n",
    "                                        weights_initializer=tf.random_uniform_initializer(0.001, 0.01),\n",
    "                                        weights_regularizer=slim.l2_regularizer(0.1),\n",
    "                                        biases_regularizer=slim.l2_regularizer(0.1),\n",
    "                                        normalizer_fn = slim.batch_norm,\n",
    "                                        normalizer_params = {\"is_training\": is_training},\n",
    "                                        reuse = reuse,\n",
    "                                        scope = scope):\n",
    "\n",
    "                    fc1 = slim.fully_connected(x, weights[0], scope='fc1')\n",
    "                    slim.dropout(fc1, 0.5)\n",
    "                    fc2 = slim.fully_connected(fc1, weights[1], scope='fc2')\n",
    "                    logits = slim.fully_connected(fc2,num_classes,activation_fn=None, weights_regularizer=None, normalizer_fn=None, scope='logits')\n",
    "                    pred = slim.softmax(logits, scope='pred')\n",
    "\n",
    "                    return logits, pred, fc1\n",
    "\n",
    "\n",
    "    def gen_train():\n",
    "        for i in range(data_train.shape[0]):\n",
    "            label = np.zeros(2)\n",
    "            label[data_label_train[i]] = 1.\n",
    "            yield data_train[i], label, data_mask_train[i]\n",
    "\n",
    "    def gen_test():\n",
    "        for i in range(data_test.shape[0]):\n",
    "            label = np.zeros(2)\n",
    "            label[data_label_test[i]] = 1.\n",
    "            yield data_test[i], label, data_mask_test[i]\n",
    "\n",
    "\n",
    "    with graph.as_default():\n",
    "\n",
    "        dataset_train = tf.data.Dataset.from_generator(gen_train, (tf.float32, tf.float32, tf.int32), ([normal_train.shape[1]],[2],[normal_train.shape[1]])).repeat(30000).shuffle(5000).batch(batch_size)\n",
    "        input_train, label_train, mask_train = dataset_train.make_one_shot_iterator().get_next()\n",
    "\n",
    "        dataset_test = tf.data.Dataset.from_generator(gen_test, (tf.float32, tf.float32, tf.int32), ([normal_train.shape[1]],[ 2],[normal_train.shape[1]])).repeat(30000).batch(data_test.shape[0])\n",
    "        input_test, label_test, mask_test = dataset_test.make_one_shot_iterator().get_next()\n",
    "\n",
    "        input_train_holder = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.float32)\n",
    "        label_train_holder = tf.placeholder(shape=[batch_size, num_classes], dtype=tf.float32)\n",
    "        mask_train_holder = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.int32)\n",
    "        logits, prediction, feature = build_net(input_train_holder)\n",
    "\n",
    "        all_test = data_test\n",
    "\n",
    "        logits_final, pred_final, _ = build_net(input_test, is_training=False)\n",
    "\n",
    "        fc_variables = [v for v in tf.trainable_variables() if v.name.find(\"NN\")!=-1]\n",
    "\n",
    "        #loss_op = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_train_holder) + tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope=\"NN\"))\n",
    "        # increase weights of entropy\n",
    "        loss_op = tf.nn.weighted_cross_entropy_with_logits(logits=logits, labels=label_train_holder, pos_weight=50) + tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope=\"NN\"))\n",
    "        loss_mean = tf.reduce_mean(loss_op, axis=0)\n",
    "        learning_rate = tf.train.exponential_decay(start_learning_rate, tf.train.get_or_create_global_step(), decay_steps=decay_step, decay_rate=decay_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # Get the encoding weights and obtain the gradients using regular SGD sovler\n",
    "\n",
    "        grads = tf.vectorized_map(lambda x: optimizer.compute_gradients(x, fc_variables), loss_op)\n",
    "        grads = [g[0] for g in grads]\n",
    "\n",
    "        # Apply importance to the gradients calculated from regular SGD solver\n",
    "\n",
    "        grad_importance = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.float32)\n",
    "        grads[0] = grads[0]*grad_importance[...,tf.newaxis]\n",
    "\n",
    "        grads = [tf.reduce_mean(g,axis=0) for g in grads]\n",
    "        \n",
    "        with tf.control_dependencies(update_ops):\n",
    "            grads_update_op = optimizer.apply_gradients(zip(grads, fc_variables))\n",
    "\n",
    "        train_correct_pred = tf.equal(tf.cast(tf.argmax(prediction, 1),tf.float32), tf.cast(tf.argmax(label_train_holder, 1),tf.float32) )\n",
    "        train_accuracy = tf.reduce_mean(tf.cast(train_correct_pred, tf.float32))\n",
    "        train_kld = tf.keras.losses.KLDivergence()(prediction, label_train_holder)\n",
    "\n",
    "        final_correct_pred = tf.equal(tf.argmax(pred_final, 1), tf.argmax(label_test, 1))\n",
    "        final_accuracy = tf.reduce_mean(tf.cast(final_correct_pred, tf.float32))\n",
    "        final_kld = tf.keras.losses.KLDivergence()(pred_final, label_test)\n",
    "\n",
    "        max_final_acc = tf.Variable(0, dtype=tf.float32, name=\"max_final_acc\", trainable=False)\n",
    "        assign_max_final_acc = max_final_acc.assign(final_accuracy)\n",
    "        \n",
    "        final_score = pred_final[:,1]\n",
    "\n",
    "    with graph.as_default():\n",
    "        actor = Actor(graph=graph, state_dim=num_input*timesteps*2+weights[0]+num_classes, action_dim=num_input*timesteps, learning_rate=actor_lr, tau=0.001, batch_size=batch_size, save_path=\"./saved_model/\"+file_appendix+\"/actor.ckpt\")\n",
    "        critic = Critic(graph=graph, state_dim=num_input*timesteps*2+weights[0]+num_classes, action_dim=num_input*timesteps, learning_rate=critic_lr, tau=0.001, gamma=0.99, save_path=\"./saved_model/\"+file_appendix+\"/critic.ckpt\")\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session(config=session_config, graph=graph) as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Probability of random exploration (p3 in Appendix D) in the behavioral policy\n",
    "        ## This probability will be decayed exponentially during training\n",
    "        EXPLORATION_RATE = args.exploration_prob\n",
    "\n",
    "        # Probability of following the heuristic (p2 in Appendix D) in the behavioral policy\n",
    "        ## This probability will be decayed exponentially during training\n",
    "        GUIDE_RATE = args.heuristic_prob\n",
    "\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "\n",
    "        data_in, label_in, s_mask = sess.run([input_train, label_train, mask_train])\n",
    "        s_1, s_2 = sess.run([logits, feature], feed_dict = {input_train_holder:data_in, label_train_holder:label_in, mask_train_holder:s_mask})\n",
    "        s = np.hstack([data_in,s_mask,s_1,s_2])\n",
    "\n",
    "        reward_list = []\n",
    "        ave_max_q_list = []\n",
    "        replay_buffer = ReplayBuffer(args.replay_buffer, random_seed=SEED)\n",
    "\n",
    "        # Run the initializer\n",
    "\n",
    "\n",
    "        max_auc = 0.\n",
    "        max_ap = 0.\n",
    "        max_acc = 0.\n",
    "        min_kld = 1000.\n",
    "\n",
    "        actor.update_target_network(sess)\n",
    "        critic.update_target_network(sess)\n",
    "\n",
    "        for step in range(training_steps):\n",
    "            rand_num = np.random.rand(1)\n",
    "\n",
    "            if rand_num <= EXPLORATION_RATE:\n",
    "                a = np.concatenate([left_truncnorm.rvs(num_input*(timesteps//2)*batch_size),right_truncnorm.rvs(num_input*(timesteps//2+1)*batch_size)])\n",
    "                np.random.shuffle(a)\n",
    "                a = a.reshape(batch_size,-1).astype(np.float32)\n",
    "\n",
    "            elif rand_num <= GUIDE_RATE+EXPLORATION_RATE and rand_num > EXPLORATION_RATE:\n",
    "                a = (1-s_mask).astype(np.float32)\n",
    "\n",
    "            else:\n",
    "                a = actor.predict(s, sess)\n",
    "\n",
    "            _, kld, test_kld = sess.run([grads_update_op, train_kld, final_kld], feed_dict={grad_importance:a, input_train_holder:data_in, label_train_holder:label_in, mask_train_holder:s_mask})\n",
    "            acc = sess.run([final_accuracy])\n",
    "            data_in, label_in, s2_mask = sess.run([input_train, label_train, mask_train])\n",
    "            s2_1, s2_2 = sess.run([logits, feature], feed_dict = {input_train_holder:data_in, label_train_holder:label_in})\n",
    "            s2 = np.hstack([data_in,s2_mask,s2_1,s2_2])\n",
    "\n",
    "            r = np.repeat(-kld, batch_size)\n",
    "            replay_buffer.add_batch([list(i) for i in zip(s,a,r,s2)])\n",
    "\n",
    "            if replay_buffer.size() > batch_size:\n",
    "                s_batch, a_batch, r_batch, s2_batch = replay_buffer.sample_batch(batch_size)\n",
    "\n",
    "                # Calculate targets\n",
    "                target_q = critic.predict_target(\n",
    "                    s2_batch, actor.predict_target(s2_batch, sess), sess)\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(batch_size):\n",
    "                    y_i.append(r_batch[k] + critic.gamma * target_q[k])\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                predicted_q_value, _ = critic.train(\n",
    "                    s_batch, a_batch, np.reshape(y_i, (batch_size, 1)), step, sess)\n",
    "\n",
    "                ave_max_q = np.amax(predicted_q_value)\n",
    "                ave_max_q_list += [ave_max_q]\n",
    "\n",
    "                # Update the actor policy using the sampled gradient\n",
    "                a_outs = actor.predict(s_batch, sess)\n",
    "                grads = critic.action_gradients(s_batch, a_outs, sess)\n",
    "                actor.train(s_batch, grads[0], step, sess)\n",
    "\n",
    "                # Update target networks\n",
    "                actor.update_target_network(sess)\n",
    "                critic.update_target_network(sess)\n",
    "\n",
    "            s = s2\n",
    "            s_mask = s2_mask\n",
    "\n",
    "            reward_list += [r[0]]\n",
    "            \n",
    "            if EXPLORATION_RATE > 0.2:\n",
    "                EXPLORATION_RATE = EXPLORATION_RATE * args.exploration_prob_decay\n",
    "            if GUIDE_RATE > 0.3:\n",
    "                GUIDE_RATE = GUIDE_RATE * args.heuristic_prob_decay\n",
    "\n",
    "\n",
    "            if step % display_step == 0 and step > 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc, train_acc = sess.run([loss_mean, final_accuracy, train_accuracy], feed_dict = {input_train_holder:data_in, label_train_holder:label_in})\n",
    "                auc = roc_auc_score(data_label_test, final_score.eval())\n",
    "                ap = average_precision_score(data_label_test, final_score.eval())\n",
    "                if np.mean(reward_list[-display_step:]) >= rl_reward_thres_for_decay:\n",
    "                    actor.decay_learning_rate(args.decay_lr_actor, sess)\n",
    "                    critic.decay_learning_rate(args.decay_lr_critic, sess)\n",
    "\n",
    "                if acc > max_acc:\n",
    "                    max_acc = acc\n",
    "                    max_auc = auc\n",
    "                    max_ap = ap\n",
    "                    min_kld = test_kld\n",
    "                    sess.run(assign_max_final_acc)\n",
    "                    saver.save(sess, \"./saved_model/\"+file_appendix+\"/best.ckpt\")\n",
    "                print (\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(np.mean(loss)) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(train_acc) + \\\n",
    "                      \", Max Final Accuracy= \", \"{:6f}\".format(max_final_acc.eval()) + \\\n",
    "                      \", Max AUC= \", \"{:6f}\".format(max_auc) + \\\n",
    "                      \", Max AP= \", \"{:6f}\".format(max_ap))\n",
    "                with open(\"./stats/rl_log/\" + file_appendix + \".txt\", \"a\") as myfile:\n",
    "                    myfile.write(\"Step \" + str(step) + \", Reward=\" + str(np.sum(reward_list[-display_step:])) + \", Minibatch Loss= \" + \"{:.4f}\".format(np.mean(loss)) + \", Training Accuracy= \" + \"{:.3f}\".format(train_acc) + \", Max Final Accuracy= \" + \"{:6f}\".format(max_final_acc.eval()) + \", Exploration= \" + \"{:6f}\".format(EXPLORATION_RATE) + \", Guide= \" + \"{:6f}\".format(GUIDE_RATE) + \"\\n\")\n",
    "        print (\"Optimization Finished!\")\n",
    "\n",
    "        print (\"Testing Accuracy:\", sess.run(max_final_acc))\n",
    "        print (\"Testing AUC:\", max_auc)\n",
    "        with open(\"./stats/TAB_GIL.txt\", \"a\") as myfile:\n",
    "            myfile.write(\"%.9f\\t%i\\t%.3f\\t%i\\t%i\\t%.9f\\t%.9f\\t%.6f\\t%.6f\\t%.6f\\n\" %(start_learning_rate, decay_step, decay_rate, weights[0], weights[1], actor_lr, critic_lr, max_final_acc.eval(), max_auc, max_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9042b9b-a72b-44fe-a1c9-3e2c520f4d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:3: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:10: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:132: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:137: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:95: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\python3.7\\lib\\site-packages\\tensorflow_core\\contrib\\layers\\python\\layers\\layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:146: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:150: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:150: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:152: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:152: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:153: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:37: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:47: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\OneDrive\\Desktop\\+DSResearch_2022Spring\\mlp_GIL\\gradient-importance-learning-spesis\\tabular_data\\qnetwork.py:137: The name tf.losses.mean_squared_error is deprecated. Please use tf.compat.v1.losses.mean_squared_error instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Program Files\\Anaconda3\\envs\\python3.7\\lib\\site-packages\\tensorflow_core\\python\\ops\\losses\\losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:188: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\xiaoy\\AppData\\Local\\Temp\\ipykernel_20112\\3337162453.py:193: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Step 10, Minibatch Loss= 17.2971, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 20, Minibatch Loss= 16.9458, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 30, Minibatch Loss= 16.6097, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 40, Minibatch Loss= 16.2764, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 50, Minibatch Loss= 15.9265, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 60, Minibatch Loss= 15.7486, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 70, Minibatch Loss= 15.4703, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 80, Minibatch Loss= 15.1559, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 90, Minibatch Loss= 14.6379, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n",
      "Step 100, Minibatch Loss= 14.5607, Training Accuracy= 1.000, Max Final Accuracy=  0.985853, Max AUC=  0.457492, Max AP=  0.012816\n"
     ]
    }
   ],
   "source": [
    "    if not args.no_gpu:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(args.gpu_idx)\n",
    "        session_config = tf.ConfigProto(log_device_placement=False)\n",
    "        session_config.gpu_options.allow_growth = True\n",
    "    else:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "        session_config = tf.ConfigProto(log_device_placement=False)\n",
    "    SEED = args.seed\n",
    "    np.random.seed(SEED)\n",
    "    tf.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    if not os.path.exists(\"./saved_model\"):\n",
    "            os.mkdir(\"./saved_model\")\n",
    "    if not os.path.exists(\"./stats\"):\n",
    "            os.mkdir(\"./stats\")\n",
    "    if not os.path.exists(\"./stats/rl_log\"):\n",
    "            os.mkdir(\"./stats/rl_log\")\n",
    "\n",
    "    # normal_train = np.loadtxt(\"./data/normal_train_all_35_missing.txt\")\n",
    "    # abnormal_train = np.loadtxt(\"./data/abnormal_train_all_35_missing.txt\")\n",
    "    # normal_test = np.loadtxt(\"./data/normal_test_all_35_missing.txt\")\n",
    "    # abnormal_test = np.loadtxt(\"./data/abnormal_test_all_35_missing.txt\")\n",
    "    normal_train = np.loadtxt(\"./data/trainA_normal_sepsis.txt\")\n",
    "    abnormal_train = np.loadtxt(\"./data/trainA_abnormal_sepsis.txt\")\n",
    "    normal_test = np.loadtxt(\"./data/testB_normal_sepsis.txt\")\n",
    "    abnormal_test = np.loadtxt(\"./data/testB_abnormal_sepsis.txt\")\n",
    "\n",
    "    data_train = np.vstack([normal_train, abnormal_train]).astype(np.float32)\n",
    "    data_label_train = np.concatenate([np.zeros(len(normal_train)), np.ones(len(abnormal_train))]).astype(np.int32)\n",
    "    data_mask_train = np.isnan(data_train).astype(np.float32)\n",
    "\n",
    "    data_test = np.vstack([normal_test, abnormal_test]).astype(np.float32)\n",
    "    data_label_test = np.concatenate([np.zeros(len(normal_test)), np.ones(len(abnormal_test))]).astype(np.int32)\n",
    "    data_mask_test = np.isnan(data_test).astype(np.float32)\n",
    "\n",
    "\n",
    "    nan_replacement = 0.\n",
    "\n",
    "    data_train[np.isnan(data_train)] = nan_replacement\n",
    "    data_test[np.isnan(data_test)] = nan_replacement\n",
    "\n",
    "\n",
    "    # Setting up the truncated normal distribution for exploration\n",
    "\n",
    "    lower, upper = 0, 1\n",
    "    mu, sigma = 0, 0.2\n",
    "    left_truncnorm = stats.truncnorm(\n",
    "        (lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n",
    "    right_truncnorm = stats.truncnorm(\n",
    "        (lower - 1.) / sigma, (upper - 1.) / sigma, loc=1., scale=sigma)\n",
    "\n",
    "    # fig, ax = plt.subplots(1, sharex=True)\n",
    "    # ax.hist(np.concatenate([left_truncnorm.rvs(10000),right_truncnorm.rvs(10000)]), normed=True)\n",
    "\n",
    "    np.random.seed(SEED)\n",
    "    tf.set_random_seed(SEED)\n",
    "    random.seed(SEED)\n",
    "\n",
    "    # RL learning rates\n",
    "    actor_lr, critic_lr = args.lr_actor, args.lr_critic\n",
    "\n",
    "    # Prediction Model Parameters\n",
    "    start_learning_rate = args.lr_prediction_model\n",
    "    decay_step = args.decay_step\n",
    "    decay_rate = args.decay_rate\n",
    "\n",
    "    # Threshold for decaying RL learning rates\n",
    "    rl_reward_thres_for_decay = -25\n",
    "\n",
    "    training_steps = args.training_steps\n",
    "    batch_size = 128 # must be a multiple of 4\n",
    "\n",
    "    # num_input = normal_train.shape[1]\n",
    "    num_input = data_train.shape[1]\n",
    "    timesteps = 1 # timesteps\n",
    "    num_classes = 2 \n",
    "\n",
    "    display_step = 10\n",
    "\n",
    "    #weights = [1000, 1000] (decrese node numbers)\n",
    "    weights = [5, 5]\n",
    "    \n",
    "    gpu = 0\n",
    "\n",
    "    graph = tf.Graph()\n",
    "\n",
    "    file_appendix = \"TAB_MLP_GIL_\" + str(start_learning_rate) + \"_\" + str(decay_step) + \"_\" + str(decay_rate) + \"_\" + str(actor_lr) + \"_\" + str(critic_lr)\n",
    "\n",
    "\n",
    "    def build_net(x, is_training=True, reuse=tf.AUTO_REUSE, graph=graph):\n",
    "\n",
    "        with graph.as_default():\n",
    "\n",
    "            with tf.variable_scope(\"NN\", reuse=tf.AUTO_REUSE) as scope:\n",
    "                with slim.arg_scope([slim.fully_connected], \n",
    "                                        activation_fn=tf.nn.relu,\n",
    "                                        weights_initializer=tf.random_uniform_initializer(0.001, 0.01),\n",
    "                                        weights_regularizer=slim.l2_regularizer(0.1),\n",
    "                                        biases_regularizer=slim.l2_regularizer(0.1),\n",
    "                                        normalizer_fn = slim.batch_norm,\n",
    "                                        normalizer_params = {\"is_training\": is_training},\n",
    "                                        reuse = reuse,\n",
    "                                        scope = scope):\n",
    "\n",
    "                    fc1 = slim.fully_connected(x, weights[0], scope='fc1')\n",
    "                    slim.dropout(fc1, 0.5)\n",
    "                    fc2 = slim.fully_connected(fc1, weights[1], scope='fc2')\n",
    "                    slim.dropout(fc2, 0.5)\n",
    "                    logits = slim.fully_connected(fc2,num_classes,activation_fn=None, weights_regularizer=None, normalizer_fn=None, scope='logits')\n",
    "                    pred = slim.softmax(logits, scope='pred')\n",
    "\n",
    "                    return logits, pred, fc1\n",
    "\n",
    "\n",
    "    def gen_train():\n",
    "        for i in range(data_train.shape[0]):\n",
    "            label = np.zeros(2)\n",
    "            label[data_label_train[i]] = 1.\n",
    "            yield data_train[i], label, data_mask_train[i]\n",
    "\n",
    "    def gen_test():\n",
    "        for i in range(data_test.shape[0]):\n",
    "            label = np.zeros(2)\n",
    "            label[data_label_test[i]] = 1.\n",
    "            yield data_test[i], label, data_mask_test[i]\n",
    "\n",
    "\n",
    "    with graph.as_default():\n",
    "\n",
    "        dataset_train = tf.data.Dataset.from_generator(gen_train, (tf.float32, tf.float32, tf.int32), ([normal_train.shape[1]],[2],[normal_train.shape[1]])).repeat(30000).shuffle(5000).batch(batch_size)\n",
    "        input_train, label_train, mask_train = dataset_train.make_one_shot_iterator().get_next()\n",
    "\n",
    "        dataset_test = tf.data.Dataset.from_generator(gen_test, (tf.float32, tf.float32, tf.int32), ([normal_train.shape[1]],[ 2],[normal_train.shape[1]])).repeat(30000).batch(data_test.shape[0])\n",
    "        input_test, label_test, mask_test = dataset_test.make_one_shot_iterator().get_next()\n",
    "\n",
    "        input_train_holder = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.float32)\n",
    "        label_train_holder = tf.placeholder(shape=[batch_size, num_classes], dtype=tf.float32)\n",
    "        mask_train_holder = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.int32)\n",
    "        logits, prediction, feature = build_net(input_train_holder)\n",
    "\n",
    "        all_test = data_test\n",
    "\n",
    "        logits_final, pred_final, _ = build_net(input_test, is_training=False)\n",
    "\n",
    "        fc_variables = [v for v in tf.trainable_variables() if v.name.find(\"NN\")!=-1]\n",
    "\n",
    "        #loss_op = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=label_train_holder) + tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope=\"NN\"))\n",
    "        # increase weights of entropy\n",
    "        loss_op = tf.nn.weighted_cross_entropy_with_logits(logits=logits, labels=label_train_holder, pos_weight=50) + tf.reduce_mean(tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope=\"NN\"))\n",
    "        loss_mean = tf.reduce_mean(loss_op, axis=0)\n",
    "        learning_rate = tf.train.exponential_decay(start_learning_rate, tf.train.get_or_create_global_step(), decay_steps=decay_step, decay_rate=decay_rate)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "\n",
    "        # Get the encoding weights and obtain the gradients using regular SGD sovler\n",
    "\n",
    "        grads = tf.vectorized_map(lambda x: optimizer.compute_gradients(x, fc_variables), loss_op)\n",
    "        grads = [g[0] for g in grads]\n",
    "\n",
    "        # Apply importance to the gradients calculated from regular SGD solver\n",
    "\n",
    "        grad_importance = tf.placeholder(shape=[batch_size, num_input*timesteps], dtype=tf.float32)\n",
    "        grads[0] = grads[0]*grad_importance[...,tf.newaxis]\n",
    "\n",
    "        grads = [tf.reduce_mean(g,axis=0) for g in grads]\n",
    "        \n",
    "        with tf.control_dependencies(update_ops):\n",
    "            grads_update_op = optimizer.apply_gradients(zip(grads, fc_variables))\n",
    "\n",
    "        train_correct_pred = tf.equal(tf.cast(tf.argmax(prediction, 1),tf.float32), tf.cast(tf.argmax(label_train_holder, 1),tf.float32) )\n",
    "        train_accuracy = tf.reduce_mean(tf.cast(train_correct_pred, tf.float32))\n",
    "        train_kld = tf.keras.losses.KLDivergence()(prediction, label_train_holder)\n",
    "\n",
    "        final_correct_pred = tf.equal(tf.argmax(pred_final, 1), tf.argmax(label_test, 1))\n",
    "        final_accuracy = tf.reduce_mean(tf.cast(final_correct_pred, tf.float32))\n",
    "        final_kld = tf.keras.losses.KLDivergence()(pred_final, label_test)\n",
    "\n",
    "        max_final_acc = tf.Variable(0, dtype=tf.float32, name=\"max_final_acc\", trainable=False)\n",
    "        assign_max_final_acc = max_final_acc.assign(final_accuracy)\n",
    "        \n",
    "        final_score = pred_final[:,1]\n",
    "\n",
    "    with graph.as_default():\n",
    "        actor = Actor(graph=graph, state_dim=num_input*timesteps*2+weights[0]+num_classes, action_dim=num_input*timesteps, learning_rate=actor_lr, tau=0.001, batch_size=batch_size, save_path=\"./saved_model/\"+file_appendix+\"/actor.ckpt\")\n",
    "        critic = Critic(graph=graph, state_dim=num_input*timesteps*2+weights[0]+num_classes, action_dim=num_input*timesteps, learning_rate=critic_lr, tau=0.001, gamma=0.99, save_path=\"./saved_model/\"+file_appendix+\"/critic.ckpt\")\n",
    "        init = tf.global_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "\n",
    "    # Start training\n",
    "    with tf.Session(config=session_config, graph=graph) as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        # Probability of random exploration (p3 in Appendix D) in the behavioral policy\n",
    "        ## This probability will be decayed exponentially during training\n",
    "        EXPLORATION_RATE = args.exploration_prob\n",
    "\n",
    "        # Probability of following the heuristic (p2 in Appendix D) in the behavioral policy\n",
    "        ## This probability will be decayed exponentially during training\n",
    "        GUIDE_RATE = args.heuristic_prob\n",
    "\n",
    "        ep_reward = 0\n",
    "        ep_ave_max_q = 0\n",
    "\n",
    "        data_in, label_in, s_mask = sess.run([input_train, label_train, mask_train])\n",
    "        s_1, s_2 = sess.run([logits, feature], feed_dict = {input_train_holder:data_in, label_train_holder:label_in, mask_train_holder:s_mask})\n",
    "        s = np.hstack([data_in,s_mask,s_1,s_2])\n",
    "\n",
    "        reward_list = []\n",
    "        ave_max_q_list = []\n",
    "        replay_buffer = ReplayBuffer(args.replay_buffer, random_seed=SEED)\n",
    "\n",
    "        # Run the initializer\n",
    "\n",
    "\n",
    "        max_auc = 0.\n",
    "        max_ap = 0.\n",
    "        max_acc = 0.\n",
    "        min_kld = 1000.\n",
    "\n",
    "        actor.update_target_network(sess)\n",
    "        critic.update_target_network(sess)\n",
    "\n",
    "        for step in range(training_steps):\n",
    "            rand_num = np.random.rand(1)\n",
    "\n",
    "            if rand_num <= EXPLORATION_RATE:\n",
    "                a = np.concatenate([left_truncnorm.rvs(num_input*(timesteps//2)*batch_size),right_truncnorm.rvs(num_input*(timesteps//2+1)*batch_size)])\n",
    "                np.random.shuffle(a)\n",
    "                a = a.reshape(batch_size,-1).astype(np.float32)\n",
    "\n",
    "            elif rand_num <= GUIDE_RATE+EXPLORATION_RATE and rand_num > EXPLORATION_RATE:\n",
    "                a = (1-s_mask).astype(np.float32)\n",
    "\n",
    "            else:\n",
    "                a = actor.predict(s, sess)\n",
    "\n",
    "            _, kld, test_kld = sess.run([grads_update_op, train_kld, final_kld], feed_dict={grad_importance:a, input_train_holder:data_in, label_train_holder:label_in, mask_train_holder:s_mask})\n",
    "            acc = sess.run([final_accuracy])\n",
    "            data_in, label_in, s2_mask = sess.run([input_train, label_train, mask_train])\n",
    "            s2_1, s2_2 = sess.run([logits, feature], feed_dict = {input_train_holder:data_in, label_train_holder:label_in})\n",
    "            s2 = np.hstack([data_in,s2_mask,s2_1,s2_2])\n",
    "\n",
    "            r = np.repeat(-kld, batch_size)\n",
    "            replay_buffer.add_batch([list(i) for i in zip(s,a,r,s2)])\n",
    "\n",
    "            if replay_buffer.size() > batch_size:\n",
    "                s_batch, a_batch, r_batch, s2_batch = replay_buffer.sample_batch(batch_size)\n",
    "\n",
    "                # Calculate targets\n",
    "                target_q = critic.predict_target(\n",
    "                    s2_batch, actor.predict_target(s2_batch, sess), sess)\n",
    "\n",
    "                y_i = []\n",
    "                for k in range(batch_size):\n",
    "                    y_i.append(r_batch[k] + critic.gamma * target_q[k])\n",
    "\n",
    "                # Update the critic given the targets\n",
    "                predicted_q_value, _ = critic.train(\n",
    "                    s_batch, a_batch, np.reshape(y_i, (batch_size, 1)), step, sess)\n",
    "\n",
    "                ave_max_q = np.amax(predicted_q_value)\n",
    "                ave_max_q_list += [ave_max_q]\n",
    "\n",
    "                # Update the actor policy using the sampled gradient\n",
    "                a_outs = actor.predict(s_batch, sess)\n",
    "                grads = critic.action_gradients(s_batch, a_outs, sess)\n",
    "                actor.train(s_batch, grads[0], step, sess)\n",
    "\n",
    "                # Update target networks\n",
    "                actor.update_target_network(sess)\n",
    "                critic.update_target_network(sess)\n",
    "\n",
    "            s = s2\n",
    "            s_mask = s2_mask\n",
    "\n",
    "            reward_list += [r[0]]\n",
    "            \n",
    "            if EXPLORATION_RATE > 0.2:\n",
    "                EXPLORATION_RATE = EXPLORATION_RATE * args.exploration_prob_decay\n",
    "            if GUIDE_RATE > 0.3:\n",
    "                GUIDE_RATE = GUIDE_RATE * args.heuristic_prob_decay\n",
    "\n",
    "\n",
    "            if step % display_step == 0 and step > 0:\n",
    "                # Calculate batch loss and accuracy\n",
    "                loss, acc, train_acc = sess.run([loss_mean, final_accuracy, train_accuracy], feed_dict = {input_train_holder:data_in, label_train_holder:label_in})\n",
    "                auc = roc_auc_score(data_label_test, final_score.eval())\n",
    "                ap = average_precision_score(data_label_test, final_score.eval())\n",
    "                if np.mean(reward_list[-display_step:]) >= rl_reward_thres_for_decay:\n",
    "                    actor.decay_learning_rate(args.decay_lr_actor, sess)\n",
    "                    critic.decay_learning_rate(args.decay_lr_critic, sess)\n",
    "\n",
    "                if acc > max_acc:\n",
    "                    max_acc = acc\n",
    "                    max_auc = auc\n",
    "                    max_ap = ap\n",
    "                    min_kld = test_kld\n",
    "                    sess.run(assign_max_final_acc)\n",
    "                    saver.save(sess, \"./saved_model/\"+file_appendix+\"/best.ckpt\")\n",
    "                print (\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(np.mean(loss)) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(train_acc) + \\\n",
    "                      \", Max Final Accuracy= \", \"{:6f}\".format(max_final_acc.eval()) + \\\n",
    "                      \", Max AUC= \", \"{:6f}\".format(max_auc) + \\\n",
    "                      \", Max AP= \", \"{:6f}\".format(max_ap))\n",
    "                with open(\"./stats/rl_log/\" + file_appendix + \".txt\", \"a\") as myfile:\n",
    "                    myfile.write(\"Step \" + str(step) + \", Reward=\" + str(np.sum(reward_list[-display_step:])) + \", Minibatch Loss= \" + \"{:.4f}\".format(np.mean(loss)) + \", Training Accuracy= \" + \"{:.3f}\".format(train_acc) + \", Max Final Accuracy= \" + \"{:6f}\".format(max_final_acc.eval()) + \", Exploration= \" + \"{:6f}\".format(EXPLORATION_RATE) + \", Guide= \" + \"{:6f}\".format(GUIDE_RATE) + \"\\n\")\n",
    "        print (\"Optimization Finished!\")\n",
    "\n",
    "        print (\"Testing Accuracy:\", sess.run(max_final_acc))\n",
    "        print (\"Testing AUC:\", max_auc)\n",
    "        with open(\"./stats/TAB_GIL.txt\", \"a\") as myfile:\n",
    "            myfile.write(\"%.9f\\t%i\\t%.3f\\t%i\\t%i\\t%.9f\\t%.9f\\t%.6f\\t%.6f\\t%.6f\\n\" %(start_learning_rate, decay_step, decay_rate, weights[0], weights[1], actor_lr, critic_lr, max_final_acc.eval(), max_auc, max_ap))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88af6a14-617a-4f00-bf77-8a152c627109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
